--- 
layout: post
title: Hadoop伪分布式配置与测试
date: 2018-11-20
tags: java
---
①解压Hadoop的压缩包  
cd /simple   
tar -zxvf /simple/soft/hadoop-2.4.1.tar.gz -C /simple/
②为hadoop配置好jdk  
cd /simple/hadoop-2.4.1/etc/hadoop/  
vi hadoop-env.sh  
增加内容如下  
export JAVA_HOME=/simple/jdk1.7.0_79
![enter descriptionhere](https://viabcde.github.io/images/201812/14.png)     
③指定hdfs的缺省名称及缺省路径地址和运行时产生文件的存储目录  
只需要hadoop目录下的core-site.xml文件即可

``` 
<!--缺省名称-->
<property>
	<name>fs.default.name</name>
	<value>hdfs://192.168.1.2:90000</value>
</property>

<!--缺省路径地址-->
<property>
	<name>fs.defaultFS</name>
	<value>hdfs://192.168.1.2:90000</value>
</property>

<!--运行时文件存储目录-->
<property>
	<name>fs.tmp.dir</name>
	<value>/simple/hadoop-2.4.1/tmp</value>
</property>
```
④制定HDFS副本的数量，名称和数据的存储路径  
只需要修改hadoop目录下的hdfs-site.xml文件即可

``` 
<!-- 副本数量-->
<property>
	<name>dfs.replication</name>
	<value>1</value>
</property>
<!-- 副本数量-->
<!-- 副本名称存储路径-->
<property>
	<name>dfs.name.dir</name>
	<value>/simple/hadoop-2.4.1/hdfs/name</value>
</property>

<!-- 副本数据存储路径-->
<property>
	<name>dfs.data.dir</name>
	<value>/simple/hadoop-2.4.1/hdfs/data</value>
</property>

```
⑤修改文件名称并指定mapred运行在yarn上  
mv mapred-site.xml.template mapred-site.xml
vi mapred.xml修改如下  

``` 
<!-- 指定mr运行在yarn上-->
<property>
	<name>mapreduce.framework.name</name>
	<value>yarn</value>
</property>

```
⑥指定yarn的老大（ResourceManager）的地址 和reducer获取数据的方式  
修改yarn-site.xml文件即可  
vi yarn-site.xml  

``` 
<!-- 指定ResourceManager的地址-->
<property>
	<name>yarn.resourcemanager.hostname</name>
	<value>192.168.1.2</value>
</property>

<!-- reducer获取数据的方式-->
<property>
	<name>yarn.nodemanager.aux-services</name>
	<value>mapreduce_shuffle</value>
</property>

```
最后，为hadoop配置环境变量  
修改profile文件即可  
vi /etc/profile 修改如下  
HADOOP_HOME=/simple/hadoop-2.4.1  
export PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
![enter descriptionhere](https://viabcde.github.io/images/201812/15.png)       
更新配置文件即可生效  source /etc/profile  
### 格式化namenode  
hdfs namenode -format  
或者  
hadoop namenode -format  
### 启动hadoop
start-dfs.sh  
### 启动yarn
start-yarn.sh
### 查看以上是否正常启动
jps 非正常则stop-all.sh然后重新启动  
![enter descriptionhere](https://viabcde.github.io/images/201812/16.png)      
### 测试hdfs和yarn
![enter descriptionhere](https://viabcde.github.io/images/201812/17.png)      
![enter descriptionhere](https://viabcde.github.io/images/201812/18.png)      

